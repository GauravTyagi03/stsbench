{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import pickle \n",
    "import os\n",
    "\n",
    "# paths\n",
    "normMUA_paths = ['../raw_data/ventral_stream/monkeyF/THINGS_normMUA.mat', '../raw_data/ventral_stream/monkeyN/THINGS_normMUA.mat']\n",
    "# things path - this should be the path you downloaded and unzipped the things dataset _things_database_images.zip\n",
    "things_folder = \"../../Downloads/object_images/\"\n",
    "things_path = \"../raw_data/ventral_stream/things_imgs.mat\" #\"./monkeyN/_logs/things_imgs.mat\"\n",
    "\n",
    "# this loads the MUA data from both monkeys in V4 recordings\n",
    "v4_range_N = (512, 768) # is monkey N channels for V4\n",
    "v4_range_F = (832, 1024) # is monkey F channels for V4\n",
    "\n",
    "\n",
    "all_oracle = []\n",
    "all_reliab = []\n",
    "all_train = []\n",
    "all_test = []\n",
    "\n",
    "for normMUA_path in normMUA_paths:\n",
    "    with h5py.File(normMUA_path, \"r\") as f:\n",
    "        if \"monkeyN\" in normMUA_path:\n",
    "            v4_range = v4_range_N\n",
    "        elif \"monkeyF\" in normMUA_path: \n",
    "            v4_range = v4_range_F\n",
    "        else:\n",
    "            raise ValueError(0)\n",
    "\n",
    "        train_MUA = np.array(f[\"train_MUA\"])[:, v4_range[0]:v4_range[1]]        # shape: (n_train_stimuli, n_electrodes)\n",
    "        test_MUA = np.array(f[\"test_MUA\"][:, v4_range[0]:v4_range[1]])          # shape: (n_test_stimuli, n_electrodes)\n",
    "        reliab = np.mean(np.array(f[\"reliab\"]), 0)[v4_range[0]:v4_range[1]]  # shape: (n_electrodes)\n",
    "        oracle = np.array(f[\"oracle\"])[v4_range[0]:v4_range[1]]            # shape: (n_electrodes)\n",
    "        all_oracle.append(oracle)\n",
    "        all_reliab.append(reliab)\n",
    "        all_train.append(train_MUA)\n",
    "        all_test.append(test_MUA)\n",
    "\n",
    "oracle = np.concatenate(all_oracle)\n",
    "reliab = np.concatenate(all_reliab)\n",
    "train_MUA = np.column_stack(all_train)\n",
    "test_MUA = np.column_stack(all_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude channels with low reliability \n",
    "include_index = reliab > 0.3\n",
    "\n",
    "oracle = oracle[include_index]\n",
    "reliab = reliab[include_index]\n",
    "train_activity = train_MUA[:, include_index]\n",
    "test_activity = test_MUA[:, include_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"things_path\": shape (22248, 1), type \"|O\">\n",
      "Decoded 22248 train image paths.\n",
      "Decoded 100 test image paths.\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(things_path, \"r\") as f:\n",
    "    def decode_references(dset):\n",
    "        \"\"\"Dereference and decode all object references in a dataset.\"\"\"\n",
    "        decoded_strings = []\n",
    "        for i in range(dset.shape[0]):  # Iterate over the first column\n",
    "            ref = dset[i][0]\n",
    "            actual_data = f[ref][()]  # Dereference\n",
    "            decoded_str = actual_data.tobytes().decode(\"utf-16-le\")  # Decode properly\n",
    "            decoded_str = decoded_str.replace(\"\\\\\", \"/\")  # Flip backslashes if needed\n",
    "            decoded_strings.append(decoded_str)        \n",
    "        return np.array(decoded_strings)\n",
    "\n",
    "    # Decode train and test image paths\n",
    "    print(f[\"train_imgs\"]['things_path'])\n",
    "    train_imgs = decode_references(f[\"train_imgs\"]['things_path'])\n",
    "    test_imgs = decode_references(f[\"test_imgs\"]['things_path'])\n",
    "\n",
    "    print(f\"Decoded {len(train_imgs)} train image paths.\")\n",
    "    print(f\"Decoded {len(test_imgs)} test image paths.\")\n",
    "\n",
    "for i in range(len(train_imgs)):\n",
    "    train_imgs[i] = os.path.splitext(os.path.basename(train_imgs[i]))[0]\n",
    "\n",
    "for i in range(len(test_imgs)):\n",
    "    test_imgs[i] = os.path.splitext(os.path.basename(test_imgs[i]))[0]\n",
    "\n",
    "test_imgs = test_imgs.astype(dtype='<U22')\n",
    "train_imgs = train_imgs.astype(dtype='<U22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dict()\n",
    "dataset[\"train_stimuli\"] = train_imgs\n",
    "dataset[\"test_stimuli\"] = test_imgs\n",
    "dataset[\"reliab\"] = reliab\n",
    "dataset[\"test_activity\"] = test_activity\n",
    "dataset[\"train_activity\"] = train_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../dataset/ventral_stream_dataset.pickle\", \"wb\") as f:\n",
    "    pickle.dump(dataset, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "def convert_images_to_videos(things_folder, output_dir = \"../dataset/ventral_stream/\"):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)    \n",
    "\n",
    "    ventral_images_path = Path(things_folder)\n",
    "\n",
    "    # Find all image files in the folder and subfolders\n",
    "    image_extensions = ['*.jpg', '*.jpeg', '*.png']\n",
    "    image_paths = []\n",
    "    for ext in image_extensions:\n",
    "        image_paths.extend(ventral_images_path.rglob(ext))\n",
    "    print(ventral_images_path)\n",
    "    for img_path in image_paths:\n",
    "        flat_name = img_path.stem + '.mp4'\n",
    "        output_path = Path(output_dir) / flat_name\n",
    "\n",
    "        image = cv2.imread(str(img_path))\n",
    "        if image is None:\n",
    "            print(f\"Warning: Could not read image {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        height, width, _ = image.shape\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        video_writer = cv2.VideoWriter(str(output_path), fourcc, 25, (width, height))\n",
    "\n",
    "        # write 5 frames of the image\n",
    "        for _ in range(5):\n",
    "            video_writer.write(image)\n",
    "\n",
    "        video_writer.release()\n",
    "        print(f\"Saved video: {output_path}\")\n",
    "\n",
    "convert_images_to_videos(things_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
