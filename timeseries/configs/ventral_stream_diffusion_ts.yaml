name: 'ventral_stream'
model_name: 'diffusion_ts'   # used by eval.py to construct image_dir

dataset_params:
  im_channels: 3
  im_size: 256
  # Path to preprocessed HDF5 created by preprocess_timeseries.py
  # Shape inside: train_timeseries (n_train, T, n_electrodes), test_timeseries (n_test, T, n_electrodes)
  timeseries_h5_path: '/oak/stanford/groups/anishm/gtyagi/stsbench/dataset/ventral_stream_timeseries_preprocessed.h5'

diffusion_params:
  num_timesteps: 1000
  beta_start: 0.00085
  beta_end: 0.012

ldm_params:
  down_channels: [ 256, 384, 512, 768 ]
  mid_channels: [ 768, 512 ]
  down_sample: [ True, True, True ]
  attn_down: [ True, True, True ]
  time_emb_dim: 512
  norm_channels: 32
  num_heads: 16
  conv_out_channels: 128
  num_down_layers: 2
  num_mid_layers: 2
  num_up_layers: 2
  use_bottleneck: False   # projection is handled upstream by TemporalNeuralConditioner
  bottleneck_dim: 50
  condition_config:
    condition_types: [ 'neural' ]
    neural_condition_config:
      neural_embed_dim: 256      # MUST equal temporal_d_model
      num_neurons: 315           # raw electrode count for ventral stream
      num_bins: 15               # T — number of temporal bins
      temporal_d_model: 256      # output dim of TemporalNeuralConditioner; must equal neural_embed_dim
      temporal_dropout: 0.0
      cond_drop_prob: 0.1

autoencoder_params:
  z_channels: 4
  codebook_size: 8192
  down_channels: [ 64, 128, 256, 256 ]
  mid_channels: [ 256, 256 ]
  down_sample: [ True, True, True ]
  attn_down: [ False, False, False ]
  norm_channels: 32
  num_heads: 4
  num_down_layers: 2
  num_mid_layers: 2
  num_up_layers: 2

train_params:
  seed: 1111
  output_dir: '/oak/stanford/groups/anishm/gtyagi/stsbench/reconstruction/logs/ventral_stream/diffusion_ts/'
  ckpt_dir: '/oak/stanford/groups/anishm/gtyagi/stsbench/reconstruction/checkpoints/ventral_stream/diffusion_ts/'
  # VQ-VAE checkpoint lives in the base reconstruction directory — reuse without retraining
  vqvae_ckpt_dir: '/oak/stanford/groups/anishm/gtyagi/stsbench/reconstruction/checkpoints/ventral_stream/diffusion/'
  ldm_batch_size: 8
  autoencoder_batch_size: 8
  disc_start: 15000
  disc_weight: 0.5
  codebook_weight: 1
  commitment_beta: 0.2
  perceptual_weight: 0.75
  kl_weight: 0.000005
  ldm_epochs: 100
  autoencoder_epochs: 15
  num_samples: 1
  num_grid_rows: 1
  ldm_lr: 0.000005
  autoencoder_lr: 0.00001
  autoencoder_acc_steps: 4
  autoencoder_img_save_steps: 500
  save_latents: False
  cf_guidance_scale: 1.0
  vae_latent_dir_name: 'vae_latents'
  vqvae_latent_dir_name: 'vqvae_latents'
  ldm_ckpt_name: 'ddpm_ckpt_neural_cond_ts.pth'
  vqvae_autoencoder_ckpt_name: 'vqvae_autoencoder_ckpt.pth'
  vae_autoencoder_ckpt_name: 'vae_autoencoder_ckpt.pth'
  vqvae_discriminator_ckpt_name: 'vqvae_discriminator_ckpt.pth'
  vae_discriminator_ckpt_name: 'vae_discriminator_ckpt.pth'
  vqvae_autoencoder_log_name: 'vqvae_training_log.txt'
  ldm_log_name: 'ldm_training_log_ts.txt'
